{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nipype.interfaces import afni as afni\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os as os\n",
    "import re as re\n",
    "import glob as glob\n",
    "import nibabel as nibabel\n",
    "from mvpa2.tutorial_suite import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "\n",
    "This notebook is a marriage of the redux analyses for SRP and some code I wrote to make getting subjects and making masks more progromatic. \n",
    "\n",
    "THis notebook was run on the data stored on SNI (so data that were aligned to the skull stripped brain from Fressurfer w/ a nim cost function).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## SETUP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nipype.interfaces.afni as afni\n",
    "import os as os\n",
    "\n",
    "def makeMask(subPrefix, labelFile, maskSuffix, fsLabels):\n",
    "    \n",
    "    \"\"\"\n",
    "    function to create a mask file for a list of freesurfer regions (fs)\n",
    "        subPrefix (string):  ubject name to use\n",
    "        \n",
    "        maksSuffix (string): name to give restulting mask\n",
    "    \n",
    "        fsLabels (list of ints): set of regions to use in mask.\n",
    "    \"\"\"\n",
    "\n",
    "    ## calc mask\n",
    "    masksCalc = afni.Calc()\n",
    "    masksCalc.inputs.in_file_a = labelFile\n",
    "    masksCalc.inputs.expr = 'amongst(a, '+ ', '.join(str(l) for l in fsLabels)+ ')'\n",
    "    masksCalc.inputs.out_file =  'calcmask'\n",
    "    masksCalc.inputs.outputtype = \"AFNI\"\n",
    "    print(masksCalc.cmdline)\n",
    "    masksCalc.run()\n",
    "\n",
    "    ## resample\n",
    "    resamp = afni.Resample()\n",
    "    resamp.inputs.in_file = 'calcmask+orig.BRIK'\n",
    "    resamp.inputs.resample_mode = 'NN'\n",
    "    resamp.inputs.master =  subPrefix + '.LSSbetas.BLOCK6.study.uber.nii' # resampling to func space\n",
    "    resamp.inputs.out_file = subPrefix + '.' + maskSuffix +  '.nii'\n",
    "    resamp.inputs.outputtype = \"NIFTI\"\n",
    "    print(resamp.cmdline)\n",
    "    resamp.run()\n",
    "\n",
    "    os.remove('calcmask+orig.BRIK')\n",
    "    os.remove('calcmask+orig.HEAD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Jim/PARC_data_special/mvpa_files\n"
     ]
    }
   ],
   "source": [
    "### SET Working directory\n",
    "\n",
    "% cd /Users/Jim/PARC_data_special/mvpa_files/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bothTest = pd.read_csv(\"/Users/Jim/Dropbox/Dissertation/data_files/bothTest_toMakeRegressors.csv\")\n",
    "subsFile = np.array(bothTest.Subject.unique())\n",
    "subsFile_prefix  = np.array(['PARC_sub_' + str(s) for s in subsFile])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARC_sub_2699\n",
      "2699\n"
     ]
    }
   ],
   "source": [
    "### get list of subs w/ file some file pattern\n",
    "\n",
    "filePattern = \".labelVolume.nii.gz\"\n",
    "betaFiles = glob.glob('*' + filePattern  + '*')\n",
    "subPrefixes = map(lambda f: re.sub(filePattern,\"\",f), betaFiles)\n",
    "subNums = map(lambda f: re.sub(\"PARC_sub_\",\"\",f), subPrefixes)\n",
    "\n",
    "print subPrefixes[0]\n",
    "print subNums[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in file folder but not behave file[]\n",
      "in behave file but no filein folder ['PARC_sub_2908']\n"
     ]
    }
   ],
   "source": [
    "## who is missing from data file? \n",
    "print \"in file folder but not behave file\" + str(subsFile_prefix[np.in1d(subPrefixes, subsFile_prefix, invert = True)])\n",
    "print \"in behave file but no filein folder \" + str(subsFile_prefix[np.in1d(subsFile_prefix, subPrefixes, invert = True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters to use - beta files, masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I've made the masks already (should be of format .nii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PARC_sub_2699',\n",
       " 'PARC_sub_2718',\n",
       " 'PARC_sub_2726',\n",
       " 'PARC_sub_2736',\n",
       " 'PARC_sub_2747',\n",
       " 'PARC_sub_2754',\n",
       " 'PARC_sub_2759',\n",
       " 'PARC_sub_2761',\n",
       " 'PARC_sub_2778',\n",
       " 'PARC_sub_2784',\n",
       " 'PARC_sub_2786',\n",
       " 'PARC_sub_2787',\n",
       " 'PARC_sub_2788',\n",
       " 'PARC_sub_2792',\n",
       " 'PARC_sub_2796',\n",
       " 'PARC_sub_2799',\n",
       " 'PARC_sub_2825',\n",
       " 'PARC_sub_2829',\n",
       " 'PARC_sub_2834',\n",
       " 'PARC_sub_2838',\n",
       " 'PARC_sub_2841',\n",
       " 'PARC_sub_2848',\n",
       " 'PARC_sub_2853',\n",
       " 'PARC_sub_2865',\n",
       " 'PARC_sub_2874',\n",
       " 'PARC_sub_2879',\n",
       " 'PARC_sub_2885',\n",
       " 'PARC_sub_2903',\n",
       " 'PARC_sub_2917',\n",
       " 'PARC_sub_2927',\n",
       " 'PARC_sub_2938',\n",
       " 'PARC_sub_2939',\n",
       " 'PARC_sub_2945',\n",
       " 'PARC_sub_2955',\n",
       " 'PARC_sub_2956',\n",
       " 'PARC_sub_2958',\n",
       " 'PARC_sub_2967',\n",
       " 'PARC_sub_2987',\n",
       " 'PARC_sub_2993',\n",
       " 'PARC_sub_3010']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### set up data ####\n",
    "# subjects = ['PARC_sub_2699', 'PARC_sub_2718', 'PARC_sub_2726', 'PARC_sub_2747', 'PARC_sub_2754', 'PARC_sub_2761', 'PARC_sub_2784', 'PARC_sub_2786', 'PARC_sub_2787',\n",
    "#             'PARC_sub_2788', 'PARC_sub_2792', 'PARC_sub_2796', 'PARC_sub_2799', 'PARC_sub_2778', 'PARC_sub_2825', 'PARC_sub_2838', 'PARC_sub_2759']\n",
    "\n",
    "# subjects = subPrefixes # subjects defined above\n",
    "\n",
    "## files to use\n",
    "# filePattern = \".labelVolume.nii.gz\"\n",
    "study_beta_prefix = 'LSSbetas.BLOCK6.study.uber'\n",
    "test_beta_prefix = 'LSSbetas.GAM.test.uber'\n",
    "mask_prefix = 'parafusi'\n",
    "mask_labels = [1007, 2007, 1016, 2016]\n",
    "csvName = 'mvpa_'+ mask_prefix +'_diss1_.csv'\n",
    "\n",
    "subPrefixes.sort()\n",
    "subjects = subPrefixes\n",
    "# in scanner clarity cutoff\n",
    "confidence_cutoff = 3\n",
    "subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing Test beta file for PARC_sub_2829\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for subj_n, subj in enumerate(subjects):\n",
    "    study_beta_name = subj + '.' + study_beta_prefix + '.nii'\n",
    "    mask_name = subj + '.' + mask_prefix + '.nii'\n",
    "    test_beta_name = subj + '.' + test_beta_prefix + '.nii'\n",
    "\n",
    "    if not os.path.exists(study_beta_name):\n",
    "        print \"missing Study beta file for \"  + subj \n",
    "    \n",
    "    if not os.path.exists(test_beta_name):\n",
    "        print \"missing Test beta file for \"  + subj \n",
    "        \n",
    "    if not os.path.exists(mask_name):\n",
    "        print \"missing mask file for \"  + subj         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing PARC_sub_2829\n"
     ]
    }
   ],
   "source": [
    "# set subject list and remove the ones not wanted\n",
    "subjects = subPrefixes\n",
    "\n",
    "\n",
    "# sub 2908 - lots of movement\n",
    "# 2829 - also lots of moevement? single beta estimation for run 5 of recall failed.\n",
    "\n",
    "probSubs = ['PARC_sub_2908','PARC_sub_2844','PARC_sub_2829']\n",
    "\n",
    "for s in probSubs:\n",
    "    if(np.in1d(s,subjects)):\n",
    "        print \"removing \" + str(s)\n",
    "        subjects.remove(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I'm going to make masks with a script on the desktop.\n",
    "\n",
    "# for subPrefix in subjects:\n",
    "# #     subPrefix = 'PARC_sub_' + str(s)\n",
    "#     maskName = subPrefix + '.' + mask_prefix + '.nii'\n",
    "#     labelFileName = subPrefix + filePattern #output name\n",
    "    \n",
    "# #     print str(mask_labels)\n",
    "#     if(os.path.exists(maskName)):\n",
    "#         print maskName  + \" Mask already exists for \" + subPrefix\n",
    "#     else: makeMask(subPrefix, labelFileName, mask_prefix, mask_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARC_sub_2699\n",
      "0.229166666667\n",
      "PARC_sub_2718\n",
      "0.5\n",
      "PARC_sub_2726\n",
      "0.65625\n",
      "PARC_sub_2736\n",
      "0.697916666667\n",
      "PARC_sub_2747\n",
      "0.416666666667\n",
      "PARC_sub_2754\n",
      "0.510416666667\n",
      "PARC_sub_2759\n",
      "0.65625\n",
      "PARC_sub_2761\n",
      "0.395833333333\n",
      "PARC_sub_2778\n",
      "0.25\n",
      "PARC_sub_2784\n",
      "0.90625\n",
      "PARC_sub_2786\n",
      "0.260416666667\n",
      "PARC_sub_2787\n",
      "0.84375\n",
      "PARC_sub_2788\n",
      "0.4375\n",
      "PARC_sub_2792\n",
      "0.864583333333\n",
      "PARC_sub_2796\n",
      "0.635416666667\n",
      "PARC_sub_2799\n",
      "0.40625\n",
      "PARC_sub_2825\n",
      "0.614583333333\n",
      "PARC_sub_2834\n",
      "0.302083333333\n",
      "PARC_sub_2838\n",
      "0.645833333333\n",
      "PARC_sub_2841\n",
      "0.614583333333\n",
      "PARC_sub_2848\n",
      "0.75\n",
      "PARC_sub_2853\n",
      "0.75\n",
      "PARC_sub_2865\n",
      "0.802083333333\n",
      "PARC_sub_2874\n",
      "0.822916666667\n",
      "PARC_sub_2879\n",
      "0.166666666667\n",
      "PARC_sub_2885\n",
      "0.6875\n",
      "PARC_sub_2903\n",
      "0.229166666667\n",
      "PARC_sub_2917\n",
      "0.270833333333\n",
      "PARC_sub_2927\n",
      "0.458333333333\n",
      "PARC_sub_2938\n",
      "0.4375\n",
      "PARC_sub_2939\n",
      "0.15625\n",
      "PARC_sub_2945\n",
      "0.552083333333\n",
      "PARC_sub_2955\n",
      "0.28125\n",
      "PARC_sub_2956\n",
      "0.5\n",
      "PARC_sub_2958\n",
      "0.416666666667\n",
      "PARC_sub_2967\n",
      "0.0729166666667\n",
      "PARC_sub_2987\n",
      "0.354166666667\n",
      "PARC_sub_2993\n",
      "0.375\n",
      "PARC_sub_3010\n",
      "0.53125\n"
     ]
    }
   ],
   "source": [
    "behave_acc = []\n",
    "inScan_acc = []\n",
    "\n",
    "for subj_n, subj in enumerate(subjects):\n",
    "\n",
    "    # load behavioral data\n",
    "    test_csv_name = subj + '_test_timingdata.csv'\n",
    "    test_data = pd.read_csv(test_csv_name, sep=',')\n",
    "    print subj\n",
    "    print float(sum(test_data.finaltest_correct))/96\n",
    "    behave_acc.append(float(sum(test_data.finaltest_correct))/96)\n",
    "    inScan_acc.append(float(sum(test_data.corrected_resp > confidence_cutoff))/96)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2699  0.9375\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2718  0.927083333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2726  0.833333333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2736  0.90625\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2747  0.927083333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2754  0.927083333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2759  0.927083333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2761  0.895833333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2778  0.979166666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2784  0.96875\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2786  0.916666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2787  0.979166666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2788  0.96875\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2792  0.947916666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2796  0.958333333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2799  0.885416666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2825  0.958333333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2834  0.9375\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2838  0.885416666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2841  0.885416666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2848  0.90625\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2853  0.958333333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2865  0.958333333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2874  0.979166666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2879  0.895833333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2885  0.885416666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2903  0.90625\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2917  0.947916666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2927  0.9375\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2938  0.885416666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2939  0.895833333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2945  0.947916666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2955  0.854166666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2956  0.958333333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2958  0.96875\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2967  0.875\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2987  0.947916666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2993  0.927083333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_3010  0.979166666667\n"
     ]
    }
   ],
   "source": [
    "study_accuracy = []\n",
    "\n",
    "for subj_n, subj in enumerate(subjects):\n",
    "    \n",
    "    # load behavioral data\n",
    "    study_csv_name = subj + '_study_timingdata.csv'\n",
    "    test_csv_name = subj + '_test_timingdata.csv'\n",
    "    study_data = pd.read_csv(study_csv_name, sep=',')\n",
    "    test_data = pd.read_csv(test_csv_name, sep=',')\n",
    "    \n",
    "    # make variables to load neural data\n",
    "    study_labels = list(study_data.imgType)\n",
    "    test_labels = list(test_data.imgType)\n",
    "    trials = np.array(range(1,97))\n",
    "    runs = np.repeat(range(1,7),16, axis= 0)\n",
    "    \n",
    "    # load neural data \n",
    "    print 'loading neural data...' \n",
    "    study_beta_name = subj + '.' + study_beta_prefix + '.nii'\n",
    "    mask_name = subj + '.' + mask_prefix + '.nii'\n",
    "    test_beta_name = subj + '.' + test_beta_prefix + '.nii'\n",
    " \n",
    "    ds_study = fmri_dataset(samples = study_beta_name, mask = mask_name, chunks= runs, targets=study_labels)\n",
    "#    ds_test = fmri_dataset(samples = test_beta_name, mask = mask_name, chunks= runs, targets=test_labels)\n",
    "    zscore(ds_study)\n",
    "    \n",
    "    ### CV study\n",
    "    print 'CV study/n'\n",
    "    clf = LinearCSVMC(C=-1)\n",
    "    cvte = CrossValidation(clf, NFoldPartitioner(),errorfx=lambda p, t: np.mean(p == t),enable_ca=['stats'])\n",
    "    cv_results = cvte(ds_study)\n",
    "    print subj + '  ' + str(np.mean(cv_results))\n",
    "    study_accuracy.append(np.mean(cv_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2699N trials correct: 49 CV acc: 0.65306122449\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2718N trials correct: 54 CV acc: 0.777777777778\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2726N trials correct: 82 CV acc: 0.634146341463\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2736N trials correct: 81 CV acc: 0.753086419753\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2747N trials correct: 43 CV acc: 0.558139534884\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2754N trials correct: 40 CV acc: 0.8\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2759N trials correct: 80 CV acc: 0.8375\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2761N trials correct: 63 CV acc: 0.619047619048\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2778N trials correct: 43 CV acc: 0.604651162791\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2784N trials correct: 96 CV acc: 0.625\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2786N trials correct: 44 CV acc: 0.681818181818\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2787N trials correct: 90 CV acc: 0.766666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2788N trials correct: 66 CV acc: 0.787878787879\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2792N trials correct: 94 CV acc: 0.585106382979\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2796N trials correct: 75 CV acc: 0.653333333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2799N trials correct: 81 CV acc: 0.765432098765\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2825N trials correct: 86 CV acc: 0.697674418605\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2834N trials correct: 76 CV acc: 0.618421052632\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2838N trials correct: 73 CV acc: 0.602739726027\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2841N trials correct: 66 CV acc: 0.545454545455\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2848N trials correct: 64 CV acc: 0.828125\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2853N trials correct: 26 CV acc: 0.769230769231\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2865N trials correct: 83 CV acc: 0.710843373494\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2874N trials correct: 86 CV acc: 0.732558139535\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2879N trials correct: 52 CV acc: 0.634615384615\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2885N trials correct: 66 CV acc: 0.621212121212\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2903N trials correct: 32 CV acc: 0.65625\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2917N trials correct: 48 CV acc: 0.729166666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2927N trials correct: 78 CV acc: 0.74358974359\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2938N trials correct: 79 CV acc: 0.632911392405\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2939N trials correct: 50 CV acc: 0.6\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2945N trials correct: 54 CV acc: 0.537037037037\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2955N trials correct: 44 CV acc: 0.704545454545\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2956N trials correct: 74 CV acc: 0.648648648649\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2958N trials correct: 58 CV acc: 0.637931034483\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2967N trials correct: 40 CV acc: 0.725\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2987N trials correct: 54 CV acc: 0.537037037037\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2993N trials correct: 76 CV acc: 0.631578947368\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_3010N trials correct: 89 CV acc: 0.662921348315\n"
     ]
    }
   ],
   "source": [
    "trainstudy_test_hicon_accuracy = []\n",
    "\n",
    "for subj_n, subj in enumerate(subjects):\n",
    "\n",
    "    # load behavioral data\n",
    "    study_csv_name = subj + '_study_timingdata.csv'\n",
    "    test_csv_name = subj + '_test_timingdata.csv'\n",
    "    study_data = pd.read_csv(study_csv_name, sep=',')\n",
    "    test_data = pd.read_csv(test_csv_name, sep=',')\n",
    "    \n",
    "    # make variables to load neural data\n",
    "    study_labels = list(study_data.imgType)\n",
    "    test_labels = list(test_data.imgType)\n",
    "    trials = np.array(range(1,97))\n",
    "    runs = np.repeat(range(1,7),16, axis= 0)\n",
    "    \n",
    "    # load neural data \n",
    "    print 'loading neural data...' \n",
    "    study_beta_name = subj + '.' + study_beta_prefix + '.nii'\n",
    "    mask_name = subj + '.' + mask_prefix + '.nii'\n",
    "    test_beta_name = subj + '.' + test_beta_prefix + '.nii'\n",
    " \n",
    "    ds_study = fmri_dataset(samples = study_beta_name, mask = mask_name, chunks= runs, targets=study_labels)\n",
    "    ds_test = fmri_dataset(samples = test_beta_name, mask = mask_name, chunks= runs, targets=test_labels)\n",
    "    zscore(ds_study)\n",
    "    zscore(ds_test)\n",
    "    \n",
    "    print 'CV study/n'\n",
    "    clf = LinearCSVMC(C=-1)\n",
    "    \n",
    "    ds_test.sa['corrected_resp'] = test_data.corrected_resp\n",
    "    ds_totest = ds_test[np.array(ds_test.sa.corrected_resp > confidence_cutoff)]\n",
    "    \n",
    "    clf = LinearCSVMC(C=-1)\n",
    "    clf.train(ds_study)\n",
    "    predictions = clf.predict(ds_totest.samples)\n",
    "    results = np.mean(predictions == ds_totest.sa.targets) \n",
    "    \n",
    "    print subj +  'N trials correct: ' + str(len(predictions)) + ' CV acc: ' + str(results) \n",
    "\n",
    "    trainstudy_test_hicon_accuracy.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds_test.sa['corrected_resp'] = test_data.corrected_resp\n",
    "ds_totest = ds_test[np.array(ds_test.sa.corrected_resp > confidence_cutoff)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2699N trials correct: 22 CV acc: 0.614583333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2718N trials correct: 48 CV acc: 0.666666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2726N trials correct: 63 CV acc: 0.697916666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2736N trials correct: 67 CV acc: 0.791666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2747N trials correct: 40 CV acc: 0.739583333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2754N trials correct: 49 CV acc: 0.71875\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2759N trials correct: 63 CV acc: 0.75\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2761N trials correct: 38 CV acc: 0.666666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2778N trials correct: 24 CV acc: 0.520833333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2784N trials correct: 87 CV acc: 0.666666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2786N trials correct: 25 CV acc: 0.666666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2787N trials correct: 81 CV acc: 0.822916666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2788N trials correct: 42 CV acc: 0.6875\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2792N trials correct: 83 CV acc: 0.572916666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2796N trials correct: 61 CV acc: 0.791666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2799N trials correct: 39 CV acc: 0.75\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2825N trials correct: 59 CV acc: 0.791666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2834N trials correct: 29 CV acc: 0.75\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2838N trials correct: 62 CV acc: 0.708333333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2841N trials correct: 59 CV acc: 0.677083333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2848N trials correct: 72 CV acc: 0.71875\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2853N trials correct: 72 CV acc: 0.822916666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2865N trials correct: 77 CV acc: 0.645833333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2874N trials correct: 79 CV acc: 0.760416666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2879N trials correct: 16 CV acc: 0.572916666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2885N trials correct: 66 CV acc: 0.572916666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2903N trials correct: 22 CV acc: 0.510416666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2917N trials correct: 26 CV acc: 0.604166666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2927N trials correct: 44 CV acc: 0.65625\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2938N trials correct: 42 CV acc: 0.78125\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2939N trials correct: 15 CV acc: 0.625\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2945N trials correct: 53 CV acc: 0.645833333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2955N trials correct: 27 CV acc: 0.572916666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2956N trials correct: 48 CV acc: 0.677083333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2958N trials correct: 40 CV acc: 0.59375\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2967N trials correct: 7 CV acc: 0.53125\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2987N trials correct: 34 CV acc: 0.479166666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2993N trials correct: 36 CV acc: 0.572916666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_3010N trials correct: 51 CV acc: 0.708333333333\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = []\n",
    "\n",
    "\n",
    "for subj_n, subj in enumerate(subjects):\n",
    "\n",
    "    # load behavioral data\n",
    "    study_csv_name = subj + '_study_timingdata.csv'\n",
    "    test_csv_name = subj + '_test_timingdata.csv'\n",
    "    study_data = pd.read_csv(study_csv_name, sep=',')\n",
    "    test_data = pd.read_csv(test_csv_name, sep=',')\n",
    "    \n",
    "    # make variables to load neural data\n",
    "    study_labels = list(study_data.imgType)\n",
    "    test_labels = list(test_data.imgType)\n",
    "    trials = np.array(range(1,97))\n",
    "    runs = np.repeat(range(1,7),16, axis= 0)\n",
    "    \n",
    "    # load neural data \n",
    "    print 'loading neural data...' \n",
    "    study_beta_name = subj + '.' + study_beta_prefix + '.nii'\n",
    "    mask_name = subj + '.' + mask_prefix + '.nii'\n",
    "    test_beta_name = subj + '.' + test_beta_prefix + '.nii'\n",
    " \n",
    "#    ds_study = fmri_dataset(samples = study_beta_name, mask = mask_name, chunks= runs, targets=study_labels)\n",
    "    ds_test = fmri_dataset(samples = test_beta_name, mask = mask_name, chunks= runs, targets=test_labels)\n",
    "    zscore(ds_test)\n",
    " \n",
    "    print 'CV study/n'\n",
    "    clf = LinearCSVMC(C=-1)\n",
    "    cvte = CrossValidation(clf, NFoldPartitioner(),errorfx=lambda p, t: np.mean(p == t),enable_ca=['stats'])\n",
    "    cv_results = cvte(ds_test)\n",
    "    print subj +  'N trials correct: ' + str(sum(test_data.finaltest_correct)) + ' CV acc: ' + str(np.mean(cv_results)) \n",
    "    test_accuracy.append(np.mean(cv_results))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2699N trials correct: 22 CV acc: 0.636363636364\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2718N trials correct: 48 CV acc: 0.708333333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2726N trials correct: 63 CV acc: 0.666666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2736N trials correct: 67 CV acc: 0.776119402985\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2747N trials correct: 40 CV acc: 0.575\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2754N trials correct: 49 CV acc: 0.816326530612\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2759N trials correct: 63 CV acc: 0.84126984127\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2761N trials correct: 38 CV acc: 0.605263157895\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2778N trials correct: 24 CV acc: 0.541666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2784N trials correct: 87 CV acc: 0.666666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2786N trials correct: 25 CV acc: 0.76\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2787N trials correct: 81 CV acc: 0.740740740741\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2788N trials correct: 42 CV acc: 0.785714285714\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2792N trials correct: 83 CV acc: 0.578313253012\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2796N trials correct: 61 CV acc: 0.606557377049\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2799N trials correct: 39 CV acc: 0.769230769231\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2825N trials correct: 59 CV acc: 0.661016949153\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2834N trials correct: 29 CV acc: 0.689655172414\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2838N trials correct: 62 CV acc: 0.612903225806\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2841N trials correct: 59 CV acc: 0.542372881356\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2848N trials correct: 72 CV acc: 0.805555555556\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2853N trials correct: 72 CV acc: 0.666666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2865N trials correct: 77 CV acc: 0.714285714286\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2874N trials correct: 79 CV acc: 0.73417721519\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2879N trials correct: 16 CV acc: 0.5625\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2885N trials correct: 66 CV acc: 0.606060606061\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2903N trials correct: 22 CV acc: 0.681818181818\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2917N trials correct: 26 CV acc: 0.884615384615\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2927N trials correct: 44 CV acc: 0.772727272727\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2938N trials correct: 42 CV acc: 0.666666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2939N trials correct: 15 CV acc: 0.533333333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2945N trials correct: 53 CV acc: 0.509433962264\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2955N trials correct: 27 CV acc: 0.740740740741\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2956N trials correct: 48 CV acc: 0.645833333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2958N trials correct: 40 CV acc: 0.625\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2967N trials correct: 7 CV acc: 0.857142857143\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2987N trials correct: 34 CV acc: 0.588235294118\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2993N trials correct: 36 CV acc: 0.555555555556\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_3010N trials correct: 51 CV acc: 0.647058823529\n"
     ]
    }
   ],
   "source": [
    "trainstudy_test_cor_accuracy = []\n",
    "\n",
    "for subj_n, subj in enumerate(subjects):\n",
    "\n",
    "    # load behavioral data\n",
    "    study_csv_name = subj + '_study_timingdata.csv'\n",
    "    test_csv_name = subj + '_test_timingdata.csv'\n",
    "    study_data = pd.read_csv(study_csv_name, sep=',')\n",
    "    test_data = pd.read_csv(test_csv_name, sep=',')\n",
    "    \n",
    "    # make variables to load neural data\n",
    "    study_labels = list(study_data.imgType)\n",
    "    test_labels = list(test_data.imgType)\n",
    "    trials = np.array(range(1,97))\n",
    "    runs = np.repeat(range(1,7),16, axis= 0)\n",
    "    \n",
    "    # load neural data \n",
    "    print 'loading neural data...' \n",
    "    study_beta_name = subj + '.' + study_beta_prefix + '.nii'\n",
    "    mask_name = subj + '.' + mask_prefix + '.nii'\n",
    "    test_beta_name = subj + '.' + test_beta_prefix + '.nii'\n",
    " \n",
    "    ds_study = fmri_dataset(samples = study_beta_name, mask = mask_name, chunks= runs, targets=study_labels)\n",
    "    ds_test = fmri_dataset(samples = test_beta_name, mask = mask_name, chunks= runs, targets=test_labels)\n",
    "    zscore(ds_study)\n",
    "    zscore(ds_test)\n",
    "    ### CV TEST\n",
    "    print 'CV study/n'\n",
    "    clf = LinearCSVMC(C=-1)\n",
    "    \n",
    "    \n",
    "    correctonly_test = test_data[np.array(test_data.finaltest_correct==1)]\n",
    "    correct_test_labels = correctonly_test.imgType\n",
    "    ds_test.sa['final_corect'] = test_data.finaltest_correct\n",
    "    ds_totest = ds_test[np.array(ds_test.sa.final_corect==1)]\n",
    "    \n",
    "    clf = LinearCSVMC(C=-1)\n",
    "    clf.train(ds_study)\n",
    "    predictions = clf.predict(ds_totest.samples)\n",
    "    results = np.mean(predictions == ds_totest.sa.targets) \n",
    "    \n",
    "    print subj +  'N trials correct: ' + str(sum(test_data.finaltest_correct)) + ' CV acc: ' + str(results) \n",
    "\n",
    "    trainstudy_test_cor_accuracy.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2699N trials correct: 74 CV acc: 0.554054054054\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2718N trials correct: 48 CV acc: 0.708333333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2726N trials correct: 33 CV acc: 0.545454545455\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2736N trials correct: 29 CV acc: 0.689655172414\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2747N trials correct: 56 CV acc: 0.571428571429\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2754N trials correct: 47 CV acc: 0.617021276596\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2759N trials correct: 33 CV acc: 0.666666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2761N trials correct: 58 CV acc: 0.637931034483\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2778N trials correct: 72 CV acc: 0.597222222222\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2784N trials correct: 9 CV acc: 0.222222222222\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2786N trials correct: 71 CV acc: 0.535211267606\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2787N trials correct: 15 CV acc: 0.933333333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2788N trials correct: 54 CV acc: 0.62962962963\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2792N trials correct: 13 CV acc: 0.692307692308\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2796N trials correct: 35 CV acc: 0.628571428571\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2799N trials correct: 57 CV acc: 0.719298245614\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2825N trials correct: 37 CV acc: 0.756756756757\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2834N trials correct: 67 CV acc: 0.626865671642\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2838N trials correct: 34 CV acc: 0.617647058824\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2841N trials correct: 37 CV acc: 0.540540540541\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2848N trials correct: 24 CV acc: 0.75\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2853N trials correct: 24 CV acc: 0.666666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2865N trials correct: 19 CV acc: 0.631578947368\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2874N trials correct: 17 CV acc: 0.647058823529\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2879N trials correct: 80 CV acc: 0.6375\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2885N trials correct: 30 CV acc: 0.5\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2903N trials correct: 74 CV acc: 0.554054054054\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2917N trials correct: 70 CV acc: 0.585714285714\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2927N trials correct: 52 CV acc: 0.634615384615\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2938N trials correct: 54 CV acc: 0.555555555556\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2939N trials correct: 81 CV acc: 0.679012345679\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2945N trials correct: 43 CV acc: 0.604651162791\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2955N trials correct: 69 CV acc: 0.521739130435\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2956N trials correct: 48 CV acc: 0.604166666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2958N trials correct: 56 CV acc: 0.517857142857\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2967N trials correct: 89 CV acc: 0.550561797753\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2987N trials correct: 62 CV acc: 0.516129032258\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2993N trials correct: 60 CV acc: 0.65\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_3010N trials correct: 45 CV acc: 0.666666666667\n"
     ]
    }
   ],
   "source": [
    "trainstudy_test_incor_accuracy = []\n",
    "\n",
    "for subj_n, subj in enumerate(subjects):\n",
    "\n",
    "    # load behavioral data\n",
    "    study_csv_name = subj + '_study_timingdata.csv'\n",
    "    test_csv_name = subj + '_test_timingdata.csv'\n",
    "    study_data = pd.read_csv(study_csv_name, sep=',')\n",
    "    test_data = pd.read_csv(test_csv_name, sep=',')\n",
    "    \n",
    "    # make variables to load neural data\n",
    "    study_labels = list(study_data.imgType)\n",
    "    test_labels = list(test_data.imgType)\n",
    "    trials = np.array(range(1,97))\n",
    "    runs = np.repeat(range(1,7),16, axis= 0)\n",
    "    \n",
    "    # load neural data \n",
    "    print 'loading neural data...' \n",
    "    study_beta_name = subj + '.' + study_beta_prefix + '.nii'\n",
    "    mask_name = subj + '.' + mask_prefix + '.nii'\n",
    "    test_beta_name = subj + '.' + test_beta_prefix + '.nii'\n",
    " \n",
    "    ds_study = fmri_dataset(samples = study_beta_name, mask = mask_name, chunks= runs, targets=study_labels)\n",
    "    ds_test = fmri_dataset(samples = test_beta_name, mask = mask_name, chunks= runs, targets=test_labels)\n",
    "    zscore(ds_study)\n",
    "    zscore(ds_test)\n",
    "    ### CV TEST\n",
    "    print 'CV study/n'\n",
    "    clf = LinearCSVMC(C=-1)\n",
    "    \n",
    "    \n",
    "    correctonly_test = test_data[test_data.finaltest_correct==0]\n",
    "    correct_test_labels = correctonly_test.imgType\n",
    "    ds_test.sa['final_corect'] = test_data.finaltest_correct\n",
    "    ds_totest = ds_test[np.array(ds_test.sa.final_corect==0)]\n",
    "    \n",
    "    clf = LinearCSVMC(C=-1)\n",
    "    clf.train(ds_study)\n",
    "    predictions = clf.predict(ds_totest.samples)\n",
    "    results = np.mean(predictions == ds_totest.sa.targets) \n",
    "    \n",
    "    print subj +  'N trials correct: ' + str(len(predictions)) + ' CV acc: ' + str(results) \n",
    "\n",
    "    trainstudy_test_incor_accuracy.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2699N trials correct: 21 CV acc: 0.666666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2718N trials correct: 40 CV acc: 0.75\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2726N trials correct: 62 CV acc: 0.677419354839\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2736N trials correct: 63 CV acc: 0.777777777778\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2747N trials correct: 35 CV acc: 0.571428571429\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2754N trials correct: 31 CV acc: 0.806451612903\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2759N trials correct: 61 CV acc: 0.868852459016\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2761N trials correct: 38 CV acc: 0.605263157895\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2778N trials correct: 22 CV acc: 0.545454545455\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2784N trials correct: 87 CV acc: 0.666666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2786N trials correct: 21 CV acc: 0.809523809524\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2787N trials correct: 79 CV acc: 0.746835443038\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2788N trials correct: 38 CV acc: 0.815789473684\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2792N trials correct: 83 CV acc: 0.578313253012\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2796N trials correct: 61 CV acc: 0.606557377049\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2799N trials correct: 38 CV acc: 0.763157894737\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2825N trials correct: 57 CV acc: 0.684210526316\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2834N trials correct: 28 CV acc: 0.678571428571\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2838N trials correct: 54 CV acc: 0.592592592593\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2841N trials correct: 54 CV acc: 0.555555555556\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2848N trials correct: 57 CV acc: 0.824561403509\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2853N trials correct: 21 CV acc: 0.761904761905\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2865N trials correct: 73 CV acc: 0.72602739726\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2874N trials correct: 77 CV acc: 0.74025974026\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2879N trials correct: 13 CV acc: 0.538461538462\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2885N trials correct: 57 CV acc: 0.59649122807\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2903N trials correct: 21 CV acc: 0.666666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2917N trials correct: 23 CV acc: 0.869565217391\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2927N trials correct: 43 CV acc: 0.767441860465\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2938N trials correct: 41 CV acc: 0.658536585366\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2939N trials correct: 15 CV acc: 0.533333333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2945N trials correct: 39 CV acc: 0.564102564103\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2955N trials correct: 25 CV acc: 0.76\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2956N trials correct: 45 CV acc: 0.644444444444\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2958N trials correct: 40 CV acc: 0.625\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2967N trials correct: 6 CV acc: 0.833333333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2987N trials correct: 33 CV acc: 0.575757575758\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2993N trials correct: 33 CV acc: 0.545454545455\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_3010N trials correct: 49 CV acc: 0.632653061224\n"
     ]
    }
   ],
   "source": [
    "#### accurate and confident \n",
    "\n",
    "trainstudy_test_hicon_cor = []\n",
    "\n",
    "for subj_n, subj in enumerate(subjects):\n",
    "\n",
    "    # load behavioral data\n",
    "    study_csv_name = subj + '_study_timingdata.csv'\n",
    "    test_csv_name = subj + '_test_timingdata.csv'\n",
    "    study_data = pd.read_csv(study_csv_name, sep=',')\n",
    "    test_data = pd.read_csv(test_csv_name, sep=',')\n",
    "    \n",
    "    # make variables to load neural data\n",
    "    study_labels = list(study_data.imgType)\n",
    "    test_labels = list(test_data.imgType)\n",
    "    trials = np.array(range(1,97))\n",
    "    runs = np.repeat(range(1,7),16, axis= 0)\n",
    "    \n",
    "    # load neural data \n",
    "    print 'loading neural data...' \n",
    "    study_beta_name = subj + '.' + study_beta_prefix + '.nii'\n",
    "    mask_name = subj + '.' + mask_prefix + '.nii'\n",
    "    test_beta_name = subj + '.' + test_beta_prefix + '.nii'\n",
    " \n",
    "    ds_study = fmri_dataset(samples = study_beta_name, mask = mask_name, chunks= runs, targets=study_labels)\n",
    "    ds_test = fmri_dataset(samples = test_beta_name, mask = mask_name, chunks= runs, targets=test_labels)\n",
    "    zscore(ds_study)\n",
    "    zscore(ds_test)\n",
    "    ### CV TEST\n",
    "    print 'CV study/n'\n",
    "    clf = LinearCSVMC(C=-1)\n",
    "    \n",
    "    \n",
    "    ds_test.sa['corrected_resp'] = test_data.corrected_resp\n",
    "    ds_test.sa['final_corect'] = test_data.finaltest_correct\n",
    "    ds_totest = ds_test[np.array(ds_test.sa.corrected_resp > confidence_cutoff)]\n",
    "    ds_totest = ds_totest[np.array(ds_totest.sa.final_corect==1)]\n",
    "#     correct_test_labels = ds_totest.sa.imgType\n",
    "    \n",
    "    clf = LinearCSVMC(C=-1)\n",
    "    clf.train(ds_study)\n",
    "    predictions = clf.predict(ds_totest.samples)\n",
    "    results = np.mean(predictions == ds_totest.sa.targets) \n",
    "    \n",
    "    print subj +  'N trials correct: ' +  str(len(predictions)) + ' CV acc: ' + str(results) \n",
    "\n",
    "    trainstudy_test_hicon_cor.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ds_test.sa['corrected_resp'] = test_data.corrected_resp\n",
    "# ds_test.sa['final_corect'] = test_data.finaltest_correct\n",
    "# ds_totest = ds_test[np.array(ds_test.sa.corrected_resp > confidence_cutoff)]\n",
    "# ds_totest = ds_totest[np.array(ds_totest.sa.final_corect==1)]\n",
    "\n",
    "# ds_totest.sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2699N trials correct: 96 CV acc: 0.572916666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2718N trials correct: 96 CV acc: 0.708333333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2726N trials correct: 96 CV acc: 0.625\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2736N trials correct: 96 CV acc: 0.75\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2747N trials correct: 96 CV acc: 0.572916666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2754N trials correct: 96 CV acc: 0.71875\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2759N trials correct: 96 CV acc: 0.78125\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2761N trials correct: 96 CV acc: 0.625\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2778N trials correct: 96 CV acc: 0.583333333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2784N trials correct: 96 CV acc: 0.625\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2786N trials correct: 96 CV acc: 0.59375\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2787N trials correct: 96 CV acc: 0.770833333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2788N trials correct: 96 CV acc: 0.697916666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2792N trials correct: 96 CV acc: 0.59375\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2796N trials correct: 96 CV acc: 0.614583333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2799N trials correct: 96 CV acc: 0.739583333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2825N trials correct: 96 CV acc: 0.697916666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2834N trials correct: 96 CV acc: 0.645833333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2838N trials correct: 96 CV acc: 0.614583333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2841N trials correct: 96 CV acc: 0.541666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2848N trials correct: 96 CV acc: 0.791666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2853N trials correct: 96 CV acc: 0.666666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2865N trials correct: 96 CV acc: 0.697916666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2874N trials correct: 96 CV acc: 0.71875\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2879N trials correct: 96 CV acc: 0.625\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2885N trials correct: 96 CV acc: 0.572916666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2903N trials correct: 96 CV acc: 0.583333333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2917N trials correct: 96 CV acc: 0.666666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2927N trials correct: 96 CV acc: 0.697916666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2938N trials correct: 96 CV acc: 0.604166666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2939N trials correct: 96 CV acc: 0.65625\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2945N trials correct: 96 CV acc: 0.552083333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2955N trials correct: 96 CV acc: 0.583333333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2956N trials correct: 96 CV acc: 0.625\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2958N trials correct: 96 CV acc: 0.5625\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2967N trials correct: 96 CV acc: 0.572916666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2987N trials correct: 96 CV acc: 0.541666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2993N trials correct: 96 CV acc: 0.614583333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_3010N trials correct: 96 CV acc: 0.65625\n"
     ]
    }
   ],
   "source": [
    "trainstudy_test_all_accuracy = []\n",
    "\n",
    "for subj_n, subj in enumerate(subjects):\n",
    "\n",
    "    # load behavioral data\n",
    "    study_csv_name = subj + '_study_timingdata.csv'\n",
    "    test_csv_name = subj + '_test_timingdata.csv'\n",
    "    study_data = pd.read_csv(study_csv_name, sep=',')\n",
    "    test_data = pd.read_csv(test_csv_name, sep=',')\n",
    "    \n",
    "    # make variables to load neural data\n",
    "    study_labels = list(study_data.imgType)\n",
    "    test_labels = list(test_data.imgType)\n",
    "    trials = np.array(range(1,97))\n",
    "    runs = np.repeat(range(1,7),16, axis= 0)\n",
    "    \n",
    "    # load neural data \n",
    "    print 'loading neural data...' \n",
    "    study_beta_name = subj + '.' + study_beta_prefix + '.nii'\n",
    "    mask_name = subj + '.' + mask_prefix + '.nii'\n",
    "    test_beta_name = subj + '.' + test_beta_prefix + '.nii'\n",
    " \n",
    "    ds_study = fmri_dataset(samples = study_beta_name, mask = mask_name, chunks= runs, targets=study_labels)\n",
    "    ds_test = fmri_dataset(samples = test_beta_name, mask = mask_name, chunks= runs, targets=test_labels)\n",
    "    zscore(ds_study)\n",
    "    zscore(ds_test)\n",
    "\n",
    "    ### CV TEST\n",
    "    print 'CV study/n'\n",
    "    clf = LinearCSVMC(C=-1)\n",
    "    \n",
    "    \n",
    "#     correctonly_test = test_data[test_data.finaltest_correct==0]\n",
    "#     correct_test_labels = correctonly_test.imgType\n",
    "#     ds_test.sa['final_corect'] = test_data.finaltest_correct\n",
    "#     ds_totest = ds_test[ds_test.sa.final_corect==0]\n",
    "    \n",
    "    clf = LinearCSVMC(C=-1)\n",
    "    clf.train(ds_study)\n",
    "    predictions = clf.predict(ds_test.samples)\n",
    "    results = np.mean(predictions == ds_test.sa.targets) \n",
    "    \n",
    "    print subj +  'N trials correct: ' + str(len(predictions)) + ' CV acc: ' + str(results) \n",
    "\n",
    "    trainstudy_test_all_accuracy.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ds_totest[np.array(ds_totest.sa.final_corect==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2699N trials correct: 22 CV acc: 0.477777777778\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2718N trials correct: 48 CV acc: 0.637896825397\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2726N trials correct: 63 CV acc: 0.668434343434\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2736N trials correct: 67 CV acc: 0.840326340326\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2747N trials correct: 40 CV acc: 0.65\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2754N trials correct: 49 CV acc: 0.606854256854\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2759N trials correct: 63 CV acc: 0.764194139194\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2761N trials correct: 38 CV acc: 0.533068783069\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2778N trials correct: 24 CV acc: 0.347222222222\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2784N trials correct: 87 CV acc: 0.696604090354\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2786N trials correct: 25 CV acc: 0.450793650794\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2787N trials correct: 81 CV acc: 0.778235653236\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2788N trials correct: 42 CV acc: 0.668560606061\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2792N trials correct: 83 CV acc: 0.541208791209\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2796N trials correct: 61 CV acc: 0.832750582751\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2799N trials correct: 39 CV acc: 0.749591149591\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2825N trials correct: 59 CV acc: 0.667592592593\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2834N trials correct: 29 CV acc: 0.747222222222\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2838N trials correct: 62 CV acc: 0.728347578348\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2841N trials correct: 59 CV acc: 0.594949494949\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2848N trials correct: 72 CV acc: 0.768921818922\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2853N trials correct: 72 CV acc: 0.769655344655\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2865N trials correct: 77 CV acc: 0.675541125541\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2874N trials correct: 79 CV acc: 0.791312853813\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2879N trials correct: 16 CV acc: 0.677777777778\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2885N trials correct: 66 CV acc: 0.536033411033\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2903N trials correct: 22 CV acc: 0.766666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2917N trials correct: 26 CV acc: 0.660714285714\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2927N trials correct: 44 CV acc: 0.695136345136\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2938N trials correct: 42 CV acc: 0.843374218374\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2939N trials correct: 15 CV acc: 0.633333333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2945N trials correct: 53 CV acc: 0.531024531025\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2955N trials correct: 27 CV acc: 0.821428571429\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2956N trials correct: 48 CV acc: 0.61525974026\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2958N trials correct: 40 CV acc: 0.686111111111\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2967N trials correct: 7 CV acc: 1.0\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2987N trials correct: 34 CV acc: 0.665873015873\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2993N trials correct: 36 CV acc: 0.638888888889\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_3010N trials correct: 51 CV acc: 0.603968253968\n"
     ]
    }
   ],
   "source": [
    "test_cor_accuracy = []\n",
    "\n",
    "\n",
    "for subj_n, subj in enumerate(subjects):\n",
    "\n",
    "    # load behavioral data\n",
    "    study_csv_name = subj + '_study_timingdata.csv'\n",
    "    test_csv_name = subj + '_test_timingdata.csv'\n",
    "    study_data = pd.read_csv(study_csv_name, sep=',')\n",
    "    test_data = pd.read_csv(test_csv_name, sep=',')\n",
    "    \n",
    "    # make variables to load neural data\n",
    "    study_labels = list(study_data.imgType)\n",
    "    test_labels = list(test_data.imgType)\n",
    "    trials = np.array(range(1,97))\n",
    "    runs = np.repeat(range(1,7),16, axis= 0)\n",
    "    \n",
    "    # load neural data \n",
    "    print 'loading neural data...' \n",
    "    study_beta_name = subj + '.' + study_beta_prefix + '.nii'\n",
    "    mask_name = subj + '.' + mask_prefix + '.nii'\n",
    "    test_beta_name = subj + '.' + test_beta_prefix + '.nii'\n",
    " \n",
    "#    ds_study = fmri_dataset(samples = study_beta_name, mask = mask_name, chunks= runs, targets=study_labels)\n",
    "    ds_test = fmri_dataset(samples = test_beta_name, mask = mask_name, chunks= runs, targets=test_labels)\n",
    "    zscore(ds_test)\n",
    "    ### CV TEST\n",
    "#     print 'CV study/n'\n",
    "#     clf = LinearCSVMC(C=-1)\n",
    "#     cvte = CrossValidation(clf, NFoldPartitioner(),errorfx=lambda p, t: np.mean(p == t),enable_ca=['stats'])\n",
    "#     cv_results = cvte(ds_test)\n",
    "#     print subj + '  ' + str(np.mean(cv_results))\n",
    "\n",
    "    correctonly_test = test_data[test_data.finaltest_correct==1]\n",
    "    correct_test_labels = correctonly_test.imgType\n",
    "    ds_test.sa['final_corect'] = test_data.finaltest_correct\n",
    "    ds_totest = ds_test[np.array(ds_test.sa.final_corect==1)]\n",
    "    \n",
    "    print 'CV study/n'\n",
    "    clf = LinearCSVMC(C=-1)\n",
    "    cvte = CrossValidation(clf, NFoldPartitioner(),errorfx=lambda p, t: np.mean(p == t),enable_ca=['stats'])\n",
    "    cv_results = cvte(ds_totest)\n",
    "    print subj +  'N trials correct: ' + str(sum(test_data.finaltest_correct)) + ' CV acc: ' + str(np.mean(cv_results)) \n",
    "    test_cor_accuracy.append(np.mean(cv_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2699N trials correct: 36 CV acc: 0.5\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2718N trials correct: 21 CV acc: 0.52380952381\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2726N trials correct: 12 CV acc: 0.666666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2736N trials correct: 11 CV acc: 0.727272727273\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2747N trials correct: 29 CV acc: 0.48275862069\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2754N trials correct: 30 CV acc: 0.533333333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2759N trials correct: 6 CV acc: 0.666666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2761N trials correct: 24 CV acc: 0.583333333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2778N trials correct: 37 CV acc: 0.513513513514\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2784N trials correct: 0 CV acc: 0.0\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2786N trials correct: 21 CV acc: 0.380952380952\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2787N trials correct: 6 CV acc: 0.833333333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2788N trials correct: 20 CV acc: 0.5\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2792N trials correct: 2 CV acc: 1.0\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2796N trials correct: 15 CV acc: 0.4\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2799N trials correct: 6 CV acc: 0.666666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2825N trials correct: 2 CV acc: 0.5\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2834N trials correct: 12 CV acc: 0.666666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2838N trials correct: 9 CV acc: 0.666666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2841N trials correct: 17 CV acc: 0.647058823529\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2848N trials correct: 13 CV acc: 0.692307692308\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2853N trials correct: 27 CV acc: 0.666666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2865N trials correct: 6 CV acc: 0.5\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2874N trials correct: 8 CV acc: 0.5\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2879N trials correct: 22 CV acc: 0.590909090909\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2885N trials correct: 20 CV acc: 0.45\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2903N trials correct: 59 CV acc: 0.525423728814\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2917N trials correct: 26 CV acc: 0.730769230769\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2927N trials correct: 18 CV acc: 0.5\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2938N trials correct: 9 CV acc: 0.555555555556\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2939N trials correct: 31 CV acc: 0.774193548387\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2945N trials correct: 26 CV acc: 0.538461538462\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2955N trials correct: 28 CV acc: 0.428571428571\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2956N trials correct: 16 CV acc: 0.5\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2958N trials correct: 27 CV acc: 0.296296296296\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2967N trials correct: 15 CV acc: 0.2\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2987N trials correct: 38 CV acc: 0.552631578947\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2993N trials correct: 5 CV acc: 0.8\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_3010N trials correct: 5 CV acc: 0.6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainstudy_test_lowcon_accuracy = []\n",
    "\n",
    "for subj_n, subj in enumerate(subjects):\n",
    "\n",
    "    # load behavioral data\n",
    "    study_csv_name = subj + '_study_timingdata.csv'\n",
    "    test_csv_name = subj + '_test_timingdata.csv'\n",
    "    study_data = pd.read_csv(study_csv_name, sep=',')\n",
    "    test_data = pd.read_csv(test_csv_name, sep=',')\n",
    "    \n",
    "    # make variables to load neural data\n",
    "    study_labels = list(study_data.imgType)\n",
    "    test_labels = list(test_data.imgType)\n",
    "    trials = np.array(range(1,97))\n",
    "    runs = np.repeat(range(1,7),16, axis= 0)\n",
    "    \n",
    "    # load neural data \n",
    "    print 'loading neural data...' \n",
    "    study_beta_name = subj + '.' + study_beta_prefix + '.nii'\n",
    "    mask_name = subj + '.' + mask_prefix + '.nii'\n",
    "    test_beta_name = subj + '.' + test_beta_prefix + '.nii'\n",
    " \n",
    "    ds_study = fmri_dataset(samples = study_beta_name, mask = mask_name, chunks= runs, targets=study_labels)\n",
    "    ds_test = fmri_dataset(samples = test_beta_name, mask = mask_name, chunks= runs, targets=test_labels)\n",
    "    zscore(ds_study)\n",
    "    zscore(ds_test)\n",
    "    ### CV TEST\n",
    "    print 'CV study/n'\n",
    "    clf = LinearCSVMC(C=-1)\n",
    "    \n",
    "\n",
    "    correctonly_test = test_data[test_data.corrected_resp < confidence_cutoff]\n",
    "    correct_test_labels = correctonly_test.imgType\n",
    "    ds_test.sa['corrected_resp'] = test_data.corrected_resp\n",
    "    ds_totest = ds_test[np.array(ds_test.sa.corrected_resp < confidence_cutoff)]\n",
    "    \n",
    "    clf = LinearCSVMC(C=-1)\n",
    "    clf.train(ds_study)\n",
    "    predictions = clf.predict(ds_totest.samples)\n",
    "    results = np.mean(predictions == ds_totest.sa.targets) \n",
    "    \n",
    "    print subj +  'N trials correct: ' + str(len(predictions))+ ' CV acc: ' + str(results) \n",
    "\n",
    "    trainstudy_test_lowcon_accuracy.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENCrec_all</th>\n",
       "      <th>ENCrec_all_cor_acc</th>\n",
       "      <th>ENCrec_all_incor_acc</th>\n",
       "      <th>ENCrec_hicon3_cor</th>\n",
       "      <th>behave_acc</th>\n",
       "      <th>encode_acc</th>\n",
       "      <th>hicon_ENCrec</th>\n",
       "      <th>inScan_hiClear_pct</th>\n",
       "      <th>lowcon_ENCrec</th>\n",
       "      <th>recall_all_acc</th>\n",
       "      <th>recall_cor_acc</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.572917</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.554054</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.510417</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.614583</td>\n",
       "      <td>0.477778</td>\n",
       "      <td>PARC_sub_2699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.637897</td>\n",
       "      <td>PARC_sub_2718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.668434</td>\n",
       "      <td>PARC_sub_2726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.840326</td>\n",
       "      <td>PARC_sub_2736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.572917</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.447917</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>PARC_sub_2747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.510417</td>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.606854</td>\n",
       "      <td>PARC_sub_2754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.837500</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.764194</td>\n",
       "      <td>PARC_sub_2759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533069</td>\n",
       "      <td>PARC_sub_2761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.447917</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.347222</td>\n",
       "      <td>PARC_sub_2778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.696604</td>\n",
       "      <td>PARC_sub_2784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.260417</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.450794</td>\n",
       "      <td>PARC_sub_2786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.746835</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.822917</td>\n",
       "      <td>0.778236</td>\n",
       "      <td>PARC_sub_2787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.668561</td>\n",
       "      <td>PARC_sub_2788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.578313</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.578313</td>\n",
       "      <td>0.864583</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.585106</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>0.541209</td>\n",
       "      <td>PARC_sub_2792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.614583</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.635417</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.832751</td>\n",
       "      <td>PARC_sub_2796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.749591</td>\n",
       "      <td>PARC_sub_2799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.614583</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.667593</td>\n",
       "      <td>PARC_sub_2825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.302083</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.618421</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.747222</td>\n",
       "      <td>PARC_sub_2834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.614583</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.602740</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.728348</td>\n",
       "      <td>PARC_sub_2838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.614583</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.677083</td>\n",
       "      <td>0.594949</td>\n",
       "      <td>PARC_sub_2841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.768922</td>\n",
       "      <td>PARC_sub_2848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.822917</td>\n",
       "      <td>0.769655</td>\n",
       "      <td>PARC_sub_2853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.726027</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.710843</td>\n",
       "      <td>0.864583</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.675541</td>\n",
       "      <td>PARC_sub_2865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.734177</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.822917</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.732558</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>0.791313</td>\n",
       "      <td>PARC_sub_2874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>PARC_sub_2879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.572917</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.621212</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>0.536033</td>\n",
       "      <td>PARC_sub_2885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.554054</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.525424</td>\n",
       "      <td>0.510417</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>PARC_sub_2903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.585714</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>PARC_sub_2917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.695136</td>\n",
       "      <td>PARC_sub_2927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.632911</td>\n",
       "      <td>0.822917</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.843374</td>\n",
       "      <td>PARC_sub_2938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.679012</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>PARC_sub_2939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.552083</td>\n",
       "      <td>0.509434</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.552083</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.531025</td>\n",
       "      <td>PARC_sub_2945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>PARC_sub_2955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.677083</td>\n",
       "      <td>0.615260</td>\n",
       "      <td>PARC_sub_2956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.517857</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.686111</td>\n",
       "      <td>PARC_sub_2958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.572917</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.550562</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.072917</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>PARC_sub_2967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.354167</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.665873</td>\n",
       "      <td>PARC_sub_2987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.614583</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>PARC_sub_2993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.632653</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.662921</td>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.603968</td>\n",
       "      <td>PARC_sub_3010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ENCrec_all  ENCrec_all_cor_acc  ENCrec_all_incor_acc  ENCrec_hicon3_cor  \\\n",
       "0     0.572917            0.636364              0.554054           0.666667   \n",
       "1     0.708333            0.708333              0.708333           0.750000   \n",
       "2     0.625000            0.666667              0.545455           0.677419   \n",
       "3     0.750000            0.776119              0.689655           0.777778   \n",
       "4     0.572917            0.575000              0.571429           0.571429   \n",
       "5     0.718750            0.816327              0.617021           0.806452   \n",
       "6     0.781250            0.841270              0.666667           0.868852   \n",
       "7     0.625000            0.605263              0.637931           0.605263   \n",
       "8     0.583333            0.541667              0.597222           0.545455   \n",
       "9     0.625000            0.666667              0.222222           0.666667   \n",
       "10    0.593750            0.760000              0.535211           0.809524   \n",
       "11    0.770833            0.740741              0.933333           0.746835   \n",
       "12    0.697917            0.785714              0.629630           0.815789   \n",
       "13    0.593750            0.578313              0.692308           0.578313   \n",
       "14    0.614583            0.606557              0.628571           0.606557   \n",
       "15    0.739583            0.769231              0.719298           0.763158   \n",
       "16    0.697917            0.661017              0.756757           0.684211   \n",
       "17    0.645833            0.689655              0.626866           0.678571   \n",
       "18    0.614583            0.612903              0.617647           0.592593   \n",
       "19    0.541667            0.542373              0.540541           0.555556   \n",
       "20    0.791667            0.805556              0.750000           0.824561   \n",
       "21    0.666667            0.666667              0.666667           0.761905   \n",
       "22    0.697917            0.714286              0.631579           0.726027   \n",
       "23    0.718750            0.734177              0.647059           0.740260   \n",
       "24    0.625000            0.562500              0.637500           0.538462   \n",
       "25    0.572917            0.606061              0.500000           0.596491   \n",
       "26    0.583333            0.681818              0.554054           0.666667   \n",
       "27    0.666667            0.884615              0.585714           0.869565   \n",
       "28    0.697917            0.772727              0.634615           0.767442   \n",
       "29    0.604167            0.666667              0.555556           0.658537   \n",
       "30    0.656250            0.533333              0.679012           0.533333   \n",
       "31    0.552083            0.509434              0.604651           0.564103   \n",
       "32    0.583333            0.740741              0.521739           0.760000   \n",
       "33    0.625000            0.645833              0.604167           0.644444   \n",
       "34    0.562500            0.625000              0.517857           0.625000   \n",
       "35    0.572917            0.857143              0.550562           0.833333   \n",
       "36    0.541667            0.588235              0.516129           0.575758   \n",
       "37    0.614583            0.555556              0.650000           0.545455   \n",
       "38    0.656250            0.647059              0.666667           0.632653   \n",
       "\n",
       "    behave_acc  encode_acc  hicon_ENCrec  inScan_hiClear_pct  lowcon_ENCrec  \\\n",
       "0     0.229167    0.937500      0.653061            0.510417       0.500000   \n",
       "1     0.500000    0.927083      0.777778            0.562500       0.523810   \n",
       "2     0.656250    0.833333      0.634146            0.854167       0.666667   \n",
       "3     0.697917    0.906250      0.753086            0.843750       0.727273   \n",
       "4     0.416667    0.927083      0.558140            0.447917       0.482759   \n",
       "5     0.510417    0.927083      0.800000            0.416667       0.533333   \n",
       "6     0.656250    0.927083      0.837500            0.833333       0.666667   \n",
       "7     0.395833    0.895833      0.619048            0.656250       0.583333   \n",
       "8     0.250000    0.979167      0.604651            0.447917       0.513514   \n",
       "9     0.906250    0.968750      0.625000            1.000000       0.000000   \n",
       "10    0.260417    0.916667      0.681818            0.458333       0.380952   \n",
       "11    0.843750    0.979167      0.766667            0.937500       0.833333   \n",
       "12    0.437500    0.968750      0.787879            0.687500       0.500000   \n",
       "13    0.864583    0.947917      0.585106            0.979167       1.000000   \n",
       "14    0.635417    0.958333      0.653333            0.781250       0.400000   \n",
       "15    0.406250    0.885417      0.765432            0.843750       0.666667   \n",
       "16    0.614583    0.958333      0.697674            0.895833       0.500000   \n",
       "17    0.302083    0.937500      0.618421            0.791667       0.666667   \n",
       "18    0.645833    0.885417      0.602740            0.760417       0.666667   \n",
       "19    0.614583    0.885417      0.545455            0.687500       0.647059   \n",
       "20    0.750000    0.906250      0.828125            0.666667       0.692308   \n",
       "21    0.750000    0.958333      0.769231            0.270833       0.666667   \n",
       "22    0.802083    0.958333      0.710843            0.864583       0.500000   \n",
       "23    0.822917    0.979167      0.732558            0.895833       0.500000   \n",
       "24    0.166667    0.895833      0.634615            0.541667       0.590909   \n",
       "25    0.687500    0.885417      0.621212            0.687500       0.450000   \n",
       "26    0.229167    0.906250      0.656250            0.333333       0.525424   \n",
       "27    0.270833    0.947917      0.729167            0.500000       0.730769   \n",
       "28    0.458333    0.937500      0.743590            0.812500       0.500000   \n",
       "29    0.437500    0.885417      0.632911            0.822917       0.555556   \n",
       "30    0.156250    0.895833      0.600000            0.520833       0.774194   \n",
       "31    0.552083    0.947917      0.537037            0.562500       0.538462   \n",
       "32    0.281250    0.854167      0.704545            0.458333       0.428571   \n",
       "33    0.500000    0.958333      0.648649            0.770833       0.500000   \n",
       "34    0.416667    0.968750      0.637931            0.604167       0.296296   \n",
       "35    0.072917    0.875000      0.725000            0.416667       0.200000   \n",
       "36    0.354167    0.947917      0.537037            0.562500       0.552632   \n",
       "37    0.375000    0.927083      0.631579            0.791667       0.800000   \n",
       "38    0.531250    0.979167      0.662921            0.927083       0.600000   \n",
       "\n",
       "    recall_all_acc  recall_cor_acc        subject  \n",
       "0         0.614583        0.477778  PARC_sub_2699  \n",
       "1         0.666667        0.637897  PARC_sub_2718  \n",
       "2         0.697917        0.668434  PARC_sub_2726  \n",
       "3         0.791667        0.840326  PARC_sub_2736  \n",
       "4         0.739583        0.650000  PARC_sub_2747  \n",
       "5         0.718750        0.606854  PARC_sub_2754  \n",
       "6         0.750000        0.764194  PARC_sub_2759  \n",
       "7         0.666667        0.533069  PARC_sub_2761  \n",
       "8         0.520833        0.347222  PARC_sub_2778  \n",
       "9         0.666667        0.696604  PARC_sub_2784  \n",
       "10        0.666667        0.450794  PARC_sub_2786  \n",
       "11        0.822917        0.778236  PARC_sub_2787  \n",
       "12        0.687500        0.668561  PARC_sub_2788  \n",
       "13        0.572917        0.541209  PARC_sub_2792  \n",
       "14        0.791667        0.832751  PARC_sub_2796  \n",
       "15        0.750000        0.749591  PARC_sub_2799  \n",
       "16        0.791667        0.667593  PARC_sub_2825  \n",
       "17        0.750000        0.747222  PARC_sub_2834  \n",
       "18        0.708333        0.728348  PARC_sub_2838  \n",
       "19        0.677083        0.594949  PARC_sub_2841  \n",
       "20        0.718750        0.768922  PARC_sub_2848  \n",
       "21        0.822917        0.769655  PARC_sub_2853  \n",
       "22        0.645833        0.675541  PARC_sub_2865  \n",
       "23        0.760417        0.791313  PARC_sub_2874  \n",
       "24        0.572917        0.677778  PARC_sub_2879  \n",
       "25        0.572917        0.536033  PARC_sub_2885  \n",
       "26        0.510417        0.766667  PARC_sub_2903  \n",
       "27        0.604167        0.660714  PARC_sub_2917  \n",
       "28        0.656250        0.695136  PARC_sub_2927  \n",
       "29        0.781250        0.843374  PARC_sub_2938  \n",
       "30        0.625000        0.633333  PARC_sub_2939  \n",
       "31        0.645833        0.531025  PARC_sub_2945  \n",
       "32        0.572917        0.821429  PARC_sub_2955  \n",
       "33        0.677083        0.615260  PARC_sub_2956  \n",
       "34        0.593750        0.686111  PARC_sub_2958  \n",
       "35        0.531250        1.000000  PARC_sub_2967  \n",
       "36        0.479167        0.665873  PARC_sub_2987  \n",
       "37        0.572917        0.638889  PARC_sub_2993  \n",
       "38        0.708333        0.603968  PARC_sub_3010  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# combine  accuracy information \n",
    "\n",
    "mvpa_data_dict = {'subject' : subjects,\n",
    "                  'encode_acc' : study_accuracy,\n",
    "                  'inScan_hiClear_pct': inScan_acc,\n",
    "                  'recall_cor_acc' : test_cor_accuracy,\n",
    "                  'ENCrec_all_cor_acc': trainstudy_test_cor_accuracy,\n",
    "                  'behave_acc' : behave_acc ,\n",
    "                  'ENCrec_all_incor_acc' : trainstudy_test_incor_accuracy ,\n",
    "                  'recall_all_acc' : test_accuracy,\n",
    "                  'ENCrec_all': trainstudy_test_all_accuracy,\n",
    "                  'hicon_ENCrec' : trainstudy_test_hicon_accuracy,\n",
    "                  'lowcon_ENCrec' : trainstudy_test_lowcon_accuracy,\n",
    "                  'ENCrec_hicon3_cor': trainstudy_test_hicon_cor\n",
    "                  }\n",
    "mvpa_data = pd.DataFrame(mvpa_data_dict)\n",
    "mvpa_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mvpa_data_old = mvpa_data\n",
    "# mvpa_data_old = mvpa_data_old.append(mvpa_data)\n",
    "# mvpa_data = mvpa_data_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mvpa_data['aparcType'] = ['Marissa']*mvpa_data.shape[0]\n",
    "mvpa_data['roi'] = [mask_prefix]* mvpa_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# csvname = 'mvpa_'+ maskSuffix +'_forSRP_.csv'\n",
    "\n",
    "csvName = 'mvpa_'+ mask_prefix +'_newAlign_fix2736_.csv'\n",
    "pd.DataFrame.to_csv(mvpa_data,csvName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mvpa_parafusi_newAlign_.csv'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## quick plotting of findings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# subInfo = pd.read_csv(\"/Users/Jim/Dropbox/Dissertation/analysis tracking/subInfo.csv\")\n",
    "# mvpa_withSub = mvpa_data.merge(subInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAGpCAYAAAA3LMlbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/z+iZPRYQ1he9wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10fded910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "pal = sns.cubehelix_palette(4, 1.5, .75, light=.6, dark=.2)\n",
    "g = sns.lmplot(\"behave_acc\", \"ENCrec_hicon3_cor\", data=mvpa_data,\n",
    "               palette=pal, size=6)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7490b27c8f75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m g = sns.lmplot(\"behave_acc\", \"encode_acc\", data=mvpa_data,\n\u001b[0m\u001b[1;32m      2\u001b[0m                palette=pal, size=6)\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# that's nice.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "g = sns.lmplot(\"behave_acc\", \"encode_acc\", data=mvpa_data,\n",
    "               palette=pal, size=6)\n",
    "# that's nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAGpCAYAAAA3LMlbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10fa02790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.lmplot(\"behave_acc\",\"recall_all_acc\",  data=mvpa_data,\n",
    "               palette=pal, size=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is pretty interesting. it looks like above chance CV classification for participants who did not so great a job on the final memory test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAGpCAYAAAA3LMlbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110343f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# g = sns.lmplot(\"behave_acc\",\"inScan_hiClear_pct\",  data=mvpa_data,\n",
    "#                palette=pal, size=6)\n",
    "\n",
    "g = sns.lmplot(\"inScan_hiClear_pct\",\"recall_all_acc\",  data=mvpa_data,\n",
    "               palette=pal, size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###  Get predictions in long form\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2699N trials correct: 96 CV acc: 0.572916666667\n",
      "PARC_sub_2699N trials correct: (from dF)55 CV acc: 0.572916666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2718N trials correct: 96 CV acc: 0.708333333333\n",
      "PARC_sub_2718N trials correct: (from dF)68 CV acc: 0.708333333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2726N trials correct: 96 CV acc: 0.625\n",
      "PARC_sub_2726N trials correct: (from dF)60 CV acc: 0.625\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2736N trials correct: 96 CV acc: 0.5625\n",
      "PARC_sub_2736N trials correct: (from dF)54 CV acc: 0.5625\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2747N trials correct: 96 CV acc: 0.572916666667\n",
      "PARC_sub_2747N trials correct: (from dF)55 CV acc: 0.572916666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2754N trials correct: 96 CV acc: 0.71875\n",
      "PARC_sub_2754N trials correct: (from dF)69 CV acc: 0.71875\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2759N trials correct: 96 CV acc: 0.78125\n",
      "PARC_sub_2759N trials correct: (from dF)75 CV acc: 0.78125\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2761N trials correct: 96 CV acc: 0.625\n",
      "PARC_sub_2761N trials correct: (from dF)60 CV acc: 0.625\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2778N trials correct: 96 CV acc: 0.583333333333\n",
      "PARC_sub_2778N trials correct: (from dF)56 CV acc: 0.583333333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2784N trials correct: 96 CV acc: 0.625\n",
      "PARC_sub_2784N trials correct: (from dF)60 CV acc: 0.625\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2786N trials correct: 96 CV acc: 0.59375\n",
      "PARC_sub_2786N trials correct: (from dF)57 CV acc: 0.59375\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2787N trials correct: 96 CV acc: 0.770833333333\n",
      "PARC_sub_2787N trials correct: (from dF)74 CV acc: 0.770833333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2788N trials correct: 96 CV acc: 0.697916666667\n",
      "PARC_sub_2788N trials correct: (from dF)67 CV acc: 0.697916666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2792N trials correct: 96 CV acc: 0.59375\n",
      "PARC_sub_2792N trials correct: (from dF)57 CV acc: 0.59375\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2796N trials correct: 96 CV acc: 0.614583333333\n",
      "PARC_sub_2796N trials correct: (from dF)59 CV acc: 0.614583333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2799N trials correct: 96 CV acc: 0.739583333333\n",
      "PARC_sub_2799N trials correct: (from dF)71 CV acc: 0.739583333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2825N trials correct: 96 CV acc: 0.697916666667\n",
      "PARC_sub_2825N trials correct: (from dF)67 CV acc: 0.697916666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2834N trials correct: 96 CV acc: 0.645833333333\n",
      "PARC_sub_2834N trials correct: (from dF)62 CV acc: 0.645833333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2838N trials correct: 96 CV acc: 0.614583333333\n",
      "PARC_sub_2838N trials correct: (from dF)59 CV acc: 0.614583333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2841N trials correct: 96 CV acc: 0.541666666667\n",
      "PARC_sub_2841N trials correct: (from dF)52 CV acc: 0.541666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2848N trials correct: 96 CV acc: 0.791666666667\n",
      "PARC_sub_2848N trials correct: (from dF)76 CV acc: 0.791666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2853N trials correct: 96 CV acc: 0.666666666667\n",
      "PARC_sub_2853N trials correct: (from dF)64 CV acc: 0.666666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2865N trials correct: 96 CV acc: 0.697916666667\n",
      "PARC_sub_2865N trials correct: (from dF)67 CV acc: 0.697916666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2874N trials correct: 96 CV acc: 0.71875\n",
      "PARC_sub_2874N trials correct: (from dF)69 CV acc: 0.71875\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2879N trials correct: 96 CV acc: 0.625\n",
      "PARC_sub_2879N trials correct: (from dF)60 CV acc: 0.625\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2885N trials correct: 96 CV acc: 0.572916666667\n",
      "PARC_sub_2885N trials correct: (from dF)55 CV acc: 0.572916666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2903N trials correct: 96 CV acc: 0.583333333333\n",
      "PARC_sub_2903N trials correct: (from dF)56 CV acc: 0.583333333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2917N trials correct: 96 CV acc: 0.666666666667\n",
      "PARC_sub_2917N trials correct: (from dF)64 CV acc: 0.666666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2927N trials correct: 96 CV acc: 0.697916666667\n",
      "PARC_sub_2927N trials correct: (from dF)67 CV acc: 0.697916666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2938N trials correct: 96 CV acc: 0.604166666667\n",
      "PARC_sub_2938N trials correct: (from dF)58 CV acc: 0.604166666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2939N trials correct: 96 CV acc: 0.65625\n",
      "PARC_sub_2939N trials correct: (from dF)63 CV acc: 0.65625\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2945N trials correct: 96 CV acc: 0.552083333333\n",
      "PARC_sub_2945N trials correct: (from dF)53 CV acc: 0.552083333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2955N trials correct: 96 CV acc: 0.583333333333\n",
      "PARC_sub_2955N trials correct: (from dF)56 CV acc: 0.583333333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2956N trials correct: 96 CV acc: 0.625\n",
      "PARC_sub_2956N trials correct: (from dF)60 CV acc: 0.625\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2958N trials correct: 96 CV acc: 0.5625\n",
      "PARC_sub_2958N trials correct: (from dF)54 CV acc: 0.5625\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2967N trials correct: 96 CV acc: 0.572916666667\n",
      "PARC_sub_2967N trials correct: (from dF)55 CV acc: 0.572916666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2987N trials correct: 96 CV acc: 0.541666666667\n",
      "PARC_sub_2987N trials correct: (from dF)52 CV acc: 0.541666666667\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_2993N trials correct: 96 CV acc: 0.614583333333\n",
      "PARC_sub_2993N trials correct: (from dF)59 CV acc: 0.614583333333\n",
      "loading neural data...\n",
      "CV study/n\n",
      "PARC_sub_3010N trials correct: 96 CV acc: 0.65625\n",
      "PARC_sub_3010N trials correct: (from dF)63 CV acc: 0.65625\n"
     ]
    }
   ],
   "source": [
    "longForm = pd.DataFrame()\n",
    "\n",
    "for subj_n, subj in enumerate(subjects):\n",
    "\n",
    "    predDf = pd.DataFrame()\n",
    "    \n",
    "    # load behavioral data\n",
    "    study_csv_name = subj + '_study_timingdata.csv'\n",
    "    test_csv_name = subj + '_test_timingdata.csv'\n",
    "    study_data = pd.read_csv(study_csv_name, sep=',')\n",
    "    test_data = pd.read_csv(test_csv_name, sep=',')\n",
    "    \n",
    "    # make variables to load neural data\n",
    "    study_labels = list(study_data.imgType)\n",
    "    test_labels = list(test_data.imgType)\n",
    "    trials = np.array(range(1,97))\n",
    "    runs = np.repeat(range(1,7),16, axis= 0)\n",
    "    \n",
    "    # load neural data \n",
    "    print 'loading neural data...' \n",
    "    study_beta_name = subj + '.' + study_beta_prefix + '.nii'\n",
    "    mask_name = subj + '.' + mask_prefix + '.nii'\n",
    "    test_beta_name = subj + '.' + test_beta_prefix + '.nii'\n",
    " \n",
    "    ds_study = fmri_dataset(samples = study_beta_name, mask = mask_name, chunks= runs, targets=study_labels)\n",
    "    ds_test = fmri_dataset(samples = test_beta_name, mask = mask_name, chunks= runs, targets=test_labels)\n",
    "    zscore(ds_study)\n",
    "    zscore(ds_test)\n",
    "\n",
    "    ### CV TEST\n",
    "    print 'CV study/n'\n",
    "    clf = LinearCSVMC(C=-1)\n",
    "    \n",
    "    \n",
    "#     correctonly_test = test_data[test_data.finaltest_correct==0]\n",
    "#     correct_test_labels = correctonly_test.imgType\n",
    "#     ds_test.sa['final_corect'] = test_data.finaltest_correct\n",
    "#     ds_totest = ds_test[ds_test.sa.final_corect==0]\n",
    "    \n",
    "    clf = LinearCSVMC(C=-1)\n",
    "    clf.train(ds_study)\n",
    "    predictions = clf.predict(ds_test.samples)\n",
    "    results = np.mean(predictions == ds_test.sa.targets)\n",
    "    \n",
    "    predDf['predictions'] = np.array(predictions)\n",
    "    predDf['subID'] = subj\n",
    "    predDf['imgFile'] = np.array(test_data.imgFile)\n",
    "    predDf['trueLabel'] = np.array(test_data.imgType)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print subj +  'N trials correct: ' + str(len(predictions)) + ' CV acc: ' + str(results) \n",
    "    print subj +  'N trials correct: (from dF)' + str(sum(predDf.predictions == predDf.trueLabel)) + ' CV acc: ' + str(results) \n",
    "    \n",
    "    longForm = longForm.append(predDf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.to_csv(longForm,\"longForm_svm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "play around w/ pymvpa classifier..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LinearCSVMC(C=-1, probability = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.train(ds_study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVMWeights(clf=LinearCSVMC(svm_impl='C_SVC', kernel=LinearLSKernel(), probability=1), auto_train=True, force_train=True)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(ds_test.samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading neural data...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### let's try switching the way that the classifier works. try using stuff from sci-kit\n",
    "\n",
    "subj = 'PARC_sub_2699'\n",
    "\n",
    "# load behavioral data\n",
    "study_csv_name = subj + '_study_timingdata.csv'\n",
    "test_csv_name = subj + '_test_timingdata.csv'\n",
    "study_data = pd.read_csv(study_csv_name, sep=',')\n",
    "test_data = pd.read_csv(test_csv_name, sep=',')\n",
    "\n",
    "# make variables to load neural data\n",
    "study_labels = list(study_data.imgType)\n",
    "test_labels = list(test_data.imgType)\n",
    "trials = np.array(range(1,97))\n",
    "runs = np.repeat(range(1,7),16, axis= 0)\n",
    "\n",
    "# load neural data \n",
    "print 'loading neural data...' \n",
    "study_beta_name = subj + '.' + study_beta_prefix + '.nii'\n",
    "mask_name = subj + '.' + mask_prefix + '.nii'\n",
    "test_beta_name = subj + '.' + test_beta_prefix + '.nii'\n",
    "\n",
    "ds_study = fmri_dataset(samples = study_beta_name, mask = mask_name, chunks= runs, targets=study_labels)\n",
    "zscore(ds_study)\n",
    "\n",
    "ds_test = fmri_dataset(samples = test_beta_name, mask = mask_name, chunks= runs, targets=test_labels)\n",
    "zscore(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from mvpa2.clfs.skl.base import SKLLearnerAdapter\n",
    "\n",
    "classifier = SKLLearnerAdapter(LogisticRegression(penalty='l2', C=1.))\n",
    "\n",
    "\n",
    "\n",
    "# ### CV study\n",
    "# print 'CV study/n'\n",
    "# clf = LinearCSVMC(C=-1)\n",
    "# cvte = CrossValidation(clf, NFoldPartitioner(),errorfx=lambda p, t: np.mean(p == t),enable_ca=['stats'])\n",
    "# cv_results = cvte(ds_study)\n",
    "# print subj + '  ' + str(np.mean(cv_results))\n",
    "# study_accuracy.append(np.mean(cv_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'# of labels': 2,\n",
       " '# of sets': 6,\n",
       " 'ACC': 0.83333333333333337,\n",
       " 'ACC%': 83.333333333333343,\n",
       " 'AUC': [0.77083333333333337, 0.89583333333333337],\n",
       " 'CHI^2': (42.833333333333329, 2.6699102936172296e-09),\n",
       " 'CORR': 80,\n",
       " 'F1': array([ 0.83673469,  0.82978723]),\n",
       " 'FDR': array([ 0.18      ,  0.15217391]),\n",
       " 'FN': array([7, 9]),\n",
       " 'FP': array([9, 7]),\n",
       " 'LOE(ACC):inter': 0.79761904761904767,\n",
       " 'LOE(ACC):p': 0.41443008250091667,\n",
       " 'LOE(ACC):r': 0.41403933560541251,\n",
       " 'LOE(ACC):slope': 0.014285714285714285,\n",
       " 'MCC': array([ 0.66724612,  0.66724612]),\n",
       " 'N': array([48, 48]),\n",
       " \"N'\": array([46, 50]),\n",
       " 'NPV': array([ 0.84782609,  0.82      ]),\n",
       " 'P': array([48, 48]),\n",
       " \"P'\": array([50, 46]),\n",
       " 'PPV': array([ 0.82      ,  0.84782609]),\n",
       " 'SPC': array([ 0.8125    ,  0.85416667]),\n",
       " 'TN': array([39, 41]),\n",
       " 'TP': array([41, 39]),\n",
       " 'TPR': array([ 0.85416667,  0.8125    ]),\n",
       " 'mean(# of labels)': 2.0,\n",
       " 'mean(ACC%)': 83.333333333333343,\n",
       " 'mean(ACC)': 0.83333333333333337,\n",
       " 'mean(AUC)': 0.83333333333333337,\n",
       " 'mean(CHI^2)': 21.416666668001618,\n",
       " 'mean(CORR)': 80.0,\n",
       " 'mean(F1)': 0.83326096396005211,\n",
       " 'mean(FDR)': 0.16608695652173913,\n",
       " 'mean(FN)': 8.0,\n",
       " 'mean(FP)': 8.0,\n",
       " 'mean(LOE(ACC):inter)': 0.79761904761904767,\n",
       " 'mean(LOE(ACC):p)': 0.41443008250091667,\n",
       " 'mean(LOE(ACC):r)': 0.41403933560541251,\n",
       " 'mean(LOE(ACC):slope)': 0.014285714285714285,\n",
       " 'mean(MCC)': 0.66724612498263924,\n",
       " \"mean(N')\": 48.0,\n",
       " 'mean(N)': 48.0,\n",
       " 'mean(NPV)': 0.8339130434782609,\n",
       " \"mean(P')\": 48.0,\n",
       " 'mean(P)': 48.0,\n",
       " 'mean(PPV)': 0.8339130434782609,\n",
       " 'mean(SPC)': 0.83333333333333326,\n",
       " 'mean(TN)': 40.0,\n",
       " 'mean(TP)': 40.0,\n",
       " 'mean(TPR)': 0.83333333333333326}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf = LinearCSVMC(C=-1)\n",
    "cvte = CrossValidation(classifier, NFoldPartitioner(),errorfx=lambda p, t: np.mean(p == t),enable_ca=['stats'])\n",
    "cvte(ds_study)\n",
    "cvte.ca.stats.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'# of labels': 2,\n",
       " '# of sets': 6,\n",
       " 'ACC': 0.85416666666666663,\n",
       " 'ACC%': 85.416666666666657,\n",
       " 'AUC': [0.90625, 0.90625],\n",
       " 'CHI^2': (48.833333333333329, 1.4154994228649734e-10),\n",
       " 'CORR': 82,\n",
       " 'F1': array([ 0.86      ,  0.84782609]),\n",
       " 'FDR': array([ 0.17307692,  0.11363636]),\n",
       " 'FN': array([5, 9]),\n",
       " 'FP': array([9, 5]),\n",
       " 'LOE(ACC):inter': 0.80952380952380953,\n",
       " 'LOE(ACC):p': 0.38093921047718865,\n",
       " 'LOE(ACC):r': 0.44136741475237479,\n",
       " 'LOE(ACC):slope': 0.01785714285714286,\n",
       " 'MCC': array([ 0.71080571,  0.71080571]),\n",
       " 'N': array([48, 48]),\n",
       " \"N'\": array([44, 52]),\n",
       " 'NPV': array([ 0.88636364,  0.82692308]),\n",
       " 'P': array([48, 48]),\n",
       " \"P'\": array([52, 44]),\n",
       " 'PPV': array([ 0.82692308,  0.88636364]),\n",
       " 'SPC': array([ 0.8125    ,  0.89583333]),\n",
       " 'TN': array([39, 43]),\n",
       " 'TP': array([43, 39]),\n",
       " 'TPR': array([ 0.89583333,  0.8125    ]),\n",
       " 'mean(# of labels)': 2.0,\n",
       " 'mean(ACC%)': 85.416666666666657,\n",
       " 'mean(ACC)': 0.85416666666666663,\n",
       " 'mean(AUC)': 0.90625,\n",
       " 'mean(CHI^2)': 24.416666666737438,\n",
       " 'mean(CORR)': 82.0,\n",
       " 'mean(F1)': 0.85391304347826091,\n",
       " 'mean(FDR)': 0.14335664335664336,\n",
       " 'mean(FN)': 7.0,\n",
       " 'mean(FP)': 7.0,\n",
       " 'mean(LOE(ACC):inter)': 0.80952380952380953,\n",
       " 'mean(LOE(ACC):p)': 0.38093921047718865,\n",
       " 'mean(LOE(ACC):r)': 0.44136741475237479,\n",
       " 'mean(LOE(ACC):slope)': 0.01785714285714286,\n",
       " 'mean(MCC)': 0.71080570850602709,\n",
       " \"mean(N')\": 48.0,\n",
       " 'mean(N)': 48.0,\n",
       " 'mean(NPV)': 0.85664335664335667,\n",
       " \"mean(P')\": 48.0,\n",
       " 'mean(P)': 48.0,\n",
       " 'mean(PPV)': 0.85664335664335667,\n",
       " 'mean(SPC)': 0.85416666666666674,\n",
       " 'mean(TN)': 41.0,\n",
       " 'mean(TP)': 41.0,\n",
       " 'mean(TPR)': 0.85416666666666674}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearCSVMC(C=-1)\n",
    "clf.get_sensitivity_analyzer()\n",
    "cvte = CrossValidation(clf, NFoldPartitioner(),errorfx=lambda p, t: np.mean(p == t),enable_ca=['stats'])\n",
    "cvte(ds_study)\n",
    "cvte.ca.stats.stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
